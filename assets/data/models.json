{
    "metadata": {
        "version": "1.1.0",
        "lastUpdated": "2025-10-29",
        "contributors": ["Mohamed El Baha & Fouad Oubari"],
        "description": "Interactive database of generative AI models"
    },
    "categories": {
        "VAE": {
            "name": "Variational Autoencoders",
            "color": "#3b82f6",
            "description": "Models based on variational encoding"
        },
        "GAN": {
            "name": "Generative Adversarial Networks",
            "color": "#22c55e",
            "description": "Models based on adversarial learning"
        },
        "Diffusion": {
            "name": "Diffusion Models",
            "color": "#f97316",
            "description": "Models based on diffusion and denoising"
        },
        "Transformer": {
            "name": "Transformer-based Models",
            "color": "#a855f7",
            "description": "Models based on Transformer architecture"
        },
        "Flow": {
            "name": "Flow-based Models",
            "color": "#2dd4bf",
            "description": "Models based on normalizing flows"
        },
        "EBM": {
            "name": "Energy-Based Models",
            "color": "#ef4444",
            "description": "Energy-based models"
        }
    },
    "linkTypes": {
        "improves-upon": {
            "label": "Improves",
            "color": "#6ee7b7",
            "description": "Direct improvement of the previous model"
        },
        "variation-of": {
            "label": "Variation of",
            "color": "#fca5a5",
            "description": "Variation or adaptation of the original model"
        },
        "used-in": {
            "label": "Used in",
            "color": "#c084fc",
            "description": "Component used in another model"
        },
        "inspired-by": {
            "label": "Inspired by",
            "color": "#fde047",
            "description": "Conceptual inspiration"
        },
        "combines": {
            "label": "Combines",
            "color": "#7dd3c0",
            "description": "Combines multiple approaches"
        }
    },
    "nodes": [
        {
            "id": "VAE",
            "name": "VAE",
            "fullName": "Variational Autoencoder",
            "category": "VAE",
            "year": 2013,
            "description": "Probabilistic generative model that learns a latent representation of data by maximizing a lower bound of the likelihood (ELBO). Combines an encoder that produces a latent distribution and a decoder that reconstructs the data.",
            "mainIdea": "Encode data into a probabilistic latent space (μ, σ) and decode to reconstruct. Uses the reparameterization trick z = μ + σ ⊙ ε where ε ~ N(0,I) to enable backpropagation through stochastic sampling.",
            "keyContributions": [
                "Introduction of the variational framework for autoencoders",
                "Reparameterization trick for training",
                "ELBO as objective function"
            ],
            "papers": [
                {
                    "title": "Auto-Encoding Variational Bayes",
                    "authors": ["Kingma, D.P.", "Welling, M."],
                    "year": 2013,
                    "url": "https://arxiv.org/abs/1312.6114",
                    "venue": "ICLR 2014"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/pytorch/examples/tree/master/vae"
                }
            ],
            "metrics": {
                "citations": 25000,
                "influence": 10
            },
            "tags": ["probabilistic", "unsupervised", "representation-learning"],
            "size": 30
        },
        {
            "id": "Beta-VAE",
            "name": "β-VAE",
            "fullName": "Beta-VAE",
            "category": "VAE",
            "year": 2017,
            "description": "Extension of VAE that encourages learning of disentangled representations by adding a hyperparameter β > 1 to the KL divergence term, forcing a more factorized representation.",
            "mainIdea": "Modify the ELBO objective to L = E[log p(x|z)] - βD_KL(q(z|x)||p(z)) where β > 1 increases the pressure on KL term, forcing a more factorized latent representation.",
            "keyContributions": [
                "Introduction of β parameter to control disentanglement",
                "Demonstration that β > 1 encourages factorized representations",
                "Metrics for evaluating disentanglement"
            ],
            "papers": [
                {
                    "title": "β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework",
                    "authors": ["Higgins, I.", "Matthey, L.", "Pal, A.", "et al."],
                    "year": 2017,
                    "url": "https://openreview.net/forum?id=Sy2fzU9gl",
                    "venue": "ICLR 2017"
                }
            ],
            "code": [
                {
                    "language": "TensorFlow",
                    "url": "https://github.com/google-research/disentanglement_lib"
                }
            ],
            "metrics": {
                "citations": 3500,
                "influence": 8
            },
            "tags": ["disentanglement", "interpretability", "representation-learning"],
            "size": 20
        },
        {
            "id": "VQ-VAE",
            "name": "VQ-VAE",
            "fullName": "Vector Quantized VAE",
            "category": "VAE",
            "year": 2017,
            "description": "VAE with discrete latent space using vector quantization. Replaces the continuous Gaussian distribution with a learned discrete codebook.",
            "mainIdea": "Use a codebook of discrete vectors and assign each encoding to the nearest vector. Enables better compression and avoids posterior collapse.",
            "keyContributions": [
                "Introduction of vector quantization in VAEs",
                "Straight-through estimator for backpropagation",
                "Better reconstruction quality than standard VAE"
            ],
            "papers": [
                {
                    "title": "Neural Discrete Representation Learning",
                    "authors": ["van den Oord, A.", "Vinyals, O.", "Kavukcuoglu, K."],
                    "year": 2017,
                    "url": "https://arxiv.org/abs/1711.00937",
                    "venue": "NeurIPS 2017"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/zalandoresearch/pytorch-vq-vae"
                }
            ],
            "metrics": {
                "citations": 4200,
                "influence": 9
            },
            "tags": ["discrete-latent", "compression", "quantization"],
            "size": 20
        },
        {
            "id": "VQ-VAE-2",
            "name": "VQ-VAE-2",
            "fullName": "Hierarchical VQ-VAE",
            "category": "VAE",
            "year": 2019,
            "description": "Hierarchical version of VQ-VAE with multiple levels of quantization to capture different scales of information.",
            "mainIdea": "Hierarchy of codebooks with autoregressive priors. The top level captures global structure, lower levels capture local details.",
            "keyContributions": [
                "Multi-scale hierarchical architecture",
                "Powerful autoregressive priors (PixelCNN)",
                "High-resolution quality image generation"
            ],
            "papers": [
                {
                    "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2",
                    "authors": ["Razavi, A.", "van den Oord, A.", "Vinyals, O."],
                    "year": 2019,
                    "url": "https://arxiv.org/abs/1906.00446",
                    "venue": "NeurIPS 2019"
                }
            ],
            "metrics": {
                "citations": 1800,
                "influence": 7
            },
            "tags": ["hierarchical", "high-resolution", "autoregressive-prior"],
            "size": 18
        },
        {
            "id": "GAN",
            "name": "GAN",
            "fullName": "Generative Adversarial Network",
            "category": "GAN",
            "year": 2014,
            "description": "Revolutionary framework with two competing networks: a generator that creates synthetic data and a discriminator that distinguishes real from fake data.",
            "mainIdea": "Adversarial training via minimax game. Generator G minimizes log(1-D(G(z))) while discriminator D maximizes log(D(x)) + log(1-D(G(z))).",
            "keyContributions": [
                "Introduction of the adversarial paradigm",
                "Implicit generation without explicit likelihood",
                "Superior generation quality compared to previous models"
            ],
            "papers": [
                {
                    "title": "Generative Adversarial Nets",
                    "authors": ["Goodfellow, I.", "Pouget-Abadie, J.", "Mirza, M.", "et al."],
                    "year": 2014,
                    "url": "https://arxiv.org/abs/1406.2661",
                    "venue": "NeurIPS 2014"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/eriklindernoren/PyTorch-GAN"
                }
            ],
            "metrics": {
                "citations": 50000,
                "influence": 10
            },
            "tags": ["adversarial", "implicit-generation", "game-theory"],
            "size": 30
        },
        {
            "id": "DCGAN",
            "name": "DCGAN",
            "fullName": "Deep Convolutional GAN",
            "category": "GAN",
            "year": 2015,
            "description": "First stable GAN architecture using convolutions. Established architectural best practices for GANs.",
            "mainIdea": "Replace fully-connected layers with convolutions. Use transposed convolutions in G, strided convolutions in D, batch norm, and no pooling.",
            "keyContributions": [
                "Architectural guidelines for stable GANs",
                "Demonstration of meaningful learned representations",
                "Vector arithmetic in latent space"
            ],
            "papers": [
                {
                    "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
                    "authors": ["Radford, A.", "Metz, L.", "Chintala, S."],
                    "year": 2015,
                    "url": "https://arxiv.org/abs/1511.06434",
                    "venue": "ICLR 2016"
                }
            ],
            "metrics": {
                "citations": 15000,
                "influence": 9
            },
            "tags": ["convolutional", "architectural-guidelines", "stable-training"],
            "size": 22
        },
        {
            "id": "StyleGAN",
            "name": "StyleGAN",
            "fullName": "Style-based GAN",
            "category": "GAN",
            "year": 2018,
            "description": "Revolutionary GAN architecture enabling fine-grained and disentangled control of style at different spatial scales.",
            "mainIdea": "Mapping network f:Z→W followed by AdaIN to inject style at each layer. Enables separate control of coarse attributes (pose) and fine details (texture).",
            "keyContributions": [
                "Mapping network for more disentangled W latent space",
                "Style injection via Adaptive Instance Normalization",
                "Mixing regularization and hierarchical style control"
            ],
            "papers": [
                {
                    "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
                    "authors": ["Karras, T.", "Laine, S.", "Aila, T."],
                    "year": 2018,
                    "url": "https://arxiv.org/abs/1812.04948",
                    "venue": "CVPR 2019"
                }
            ],
            "code": [
                {
                    "language": "TensorFlow",
                    "url": "https://github.com/NVlabs/stylegan"
                }
            ],
            "metrics": {
                "citations": 8000,
                "influence": 10
            },
            "tags": ["style-control", "high-quality", "disentanglement"],
            "size": 25
        },
        {
            "id": "DDPM",
            "name": "DDPM",
            "fullName": "Denoising Diffusion Probabilistic Models",
            "category": "Diffusion",
            "year": 2020,
            "description": "Generative model based on inverting a diffusion process that progressively adds Gaussian noise to data.",
            "mainIdea": "Fixed forward process q(x_t|x_{t-1}) adding noise, learned reverse process p_θ(x_{t-1}|x_t) for denoising. Simplified objective: predict noise ε.",
            "keyContributions": [
                "Simplification of the variational objective",
                "Connection with score matching",
                "Superior quality compared to GANs on several metrics"
            ],
            "papers": [
                {
                    "title": "Denoising Diffusion Probabilistic Models",
                    "authors": ["Ho, J.", "Jain, A.", "Abbeel, P."],
                    "year": 2020,
                    "url": "https://arxiv.org/abs/2006.11239",
                    "venue": "NeurIPS 2020"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/hojonathanho/diffusion"
                }
            ],
            "metrics": {
                "citations": 7000,
                "influence": 10
            },
            "tags": ["denoising", "probabilistic", "score-based"],
            "size": 30
        },
        {
            "id": "StableDiffusion",
            "name": "Stable Diffusion",
            "fullName": "Latent Diffusion Model",
            "category": "Diffusion",
            "year": 2021,
            "description": "Diffusion in the latent space of a pre-trained VAE, drastically reducing computational costs while maintaining quality.",
            "mainIdea": "VAE encoder E compresses x→z, diffusion in latent space z, VAE decoder D reconstructs z→x. Cross-attention for textual conditioning.",
            "keyContributions": [
                "Efficient diffusion in latent space",
                "U-Net architecture with cross-attention",
                "Democratization of text-to-image generation"
            ],
            "papers": [
                {
                    "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
                    "authors": ["Rombach, R.", "Blattmann, A.", "Lorenz, D.", "et al."],
                    "year": 2021,
                    "url": "https://arxiv.org/abs/2112.10752",
                    "venue": "CVPR 2022"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/CompVis/stable-diffusion"
                }
            ],
            "metrics": {
                "citations": 5000,
                "influence": 10
            },
            "tags": ["latent-space", "text-to-image", "efficient"],
            "size": 25
        },
        {
            "id": "GPT",
            "name": "GPT",
            "fullName": "Generative Pre-trained Transformer",
            "category": "Transformer",
            "year": 2018,
            "description": "First large-scale language model using only the Transformer decoder architecture for autoregressive generation.",
            "mainIdea": "Unsupervised pre-training on next token prediction, then supervised fine-tuning. Decoder-only Transformer architecture with causal attention.",
            "keyContributions": [
                "Demonstration of large-scale generative pre-training",
                "Efficient transfer learning for NLP",
                "Decoder-only architecture for generation"
            ],
            "papers": [
                {
                    "title": "Improving Language Understanding by Generative Pre-Training",
                    "authors": ["Radford, A.", "Narasimhan, K.", "Salimans, T.", "Sutskever, I."],
                    "year": 2018,
                    "url": "https://openai.com/research/language-unsupervised",
                    "venue": "OpenAI Blog"
                }
            ],
            "metrics": {
                "citations": 10000,
                "influence": 9
            },
            "tags": ["language-model", "pre-training", "autoregressive"],
            "size": 30
        },
        {
            "id": "CVAE",
            "name": "CVAE",
            "fullName": "Conditional Variational Autoencoder",
            "category": "VAE",
            "year": 2015,
            "description": "Extends the VAE to allow conditional generation by incorporating labels or attributes into both encoder and decoder.",
            "mainIdea": "Model p(x|y) via latent variable z, optimizing conditional ELBO; enables label-conditioned generation.",
            "keyContributions": [
              "Introduced conditional generative modeling for VAEs",
              "Enabled controllable synthesis and label-based generation"
            ],
            "papers": [
              {
                "title": "Conditional Variational Autoencoder",
                "authors": ["Sohn, K.", "Lee, H.", "Yan, X."],
                "year": 2015,
                "url": "https://arxiv.org/abs/1511.06335",
                "venue": "NIPS 2015"
              }
            ],
            "metrics": {"citations": 6000, "influence": 7},
            "tags": ["conditional", "representation-learning", "generative"],
            "size": 18
          },
          {
            "id": "IWAE",
            "name": "IWAE",
            "fullName": "Importance Weighted Autoencoder",
            "category": "VAE",
            "year": 2015,
            "description": "Tightens the variational lower bound using multiple importance-weighted samples, improving likelihood estimates.",
            "mainIdea": "Uses multiple samples from q(z|x) to compute a tighter bound on log-likelihood, improving model learning.",
            "keyContributions": [
              "Introduced importance weighting for tighter ELBO",
              "Improved generative likelihood estimation"
            ],
            "papers": [
              {
                "title": "Importance Weighted Autoencoders",
                "authors": ["Burda, Y.", "Grosse, R.", "Salakhutdinov, R."],
                "year": 2015,
                "url": "https://arxiv.org/abs/1509.00519",
                "venue": "ICLR 2016"
              }
            ],
            "metrics": {"citations": 4000, "influence": 6},
            "tags": ["variational", "likelihood", "theory"],
            "size": 17
          },
          {
            "id": "NVAE",
            "name": "NVAE",
            "fullName": "Neural VAE",
            "category": "VAE",
            "year": 2020,
            "description": "Hierarchical convolutional VAE that scales to large, high-resolution image synthesis.",
            "mainIdea": "Uses deep hierarchical latent structure and normalizing flows in latent space for better flexibility and image quality.",
            "keyContributions": [
              "Hierarchical latent structure",
              "Scalable architecture for large images"
            ],
            "papers": [
              {
                "title": "NVAE: A Deep Hierarchical Variational Autoencoder",
                "authors": ["Vahdat, A.", "Kautz, J."],
                "year": 2020,
                "url": "https://arxiv.org/abs/2007.03898",
                "venue": "NeurIPS 2020"
              }
            ],
            "metrics": {"citations": 700, "influence": 7},
            "tags": ["hierarchical", "image-generation"],
            "size": 18
          },
          {
            "id": "Diffusion-VAE",
            "name": "Diffusion-VAE",
            "fullName": "Diffusion Variational Autoencoder",
            "category": "VAE",
            "year": 2022,
            "description": "Integrates diffusion processes into the latent space of VAEs, improving sample fidelity and robustness.",
            "mainIdea": "Combines diffusion noise modeling and VAE latent regularization, bridging the two paradigms.",
            "keyContributions": [
              "Bridge between VAEs and diffusion models",
              "Improved generative performance"
            ],
            "metrics": {"citations": 300, "influence": 6},
            "tags": ["hybrid", "diffusion", "vae"],
            "size": 17
          },
      
          {
            "id": "cGAN",
            "name": "cGAN",
            "fullName": "Conditional GAN",
            "category": "GAN",
            "year": 2014,
            "description": "Extends GANs by conditioning both generator and discriminator on auxiliary information (labels or attributes).",
            "mainIdea": "Input y concatenated with z and x for G and D respectively to enforce conditional generation.",
            "keyContributions": [
              "Introduced conditioning in GANs",
              "Foundation for class-conditional synthesis"
            ],
            "metrics": {"citations": 8000, "influence": 8},
            "tags": ["conditional", "adversarial"],
            "size": 20
          },
          {
            "id": "Pix2Pix",
            "name": "Pix2Pix",
            "fullName": "Image-to-Image Translation GAN",
            "category": "GAN",
            "year": 2016,
            "description": "Uses paired data to learn direct image-to-image mapping via conditional GAN loss.",
            "mainIdea": "Combines L1 reconstruction with adversarial loss for paired translation tasks.",
            "metrics": {"citations": 17000, "influence": 8},
            "tags": ["image-translation", "conditional", "supervised"],
            "size": 22
          },
          {
            "id": "CycleGAN",
            "name": "CycleGAN",
            "fullName": "Cycle-Consistent GAN",
            "category": "GAN",
            "year": 2017,
            "description": "Learns image translation between two domains without paired data using cycle-consistency loss.",
            "mainIdea": "Two GANs G:X→Y and F:Y→X trained with cycle-consistency loss to ensure invertibility.",
            "metrics": {"citations": 30000, "influence": 9},
            "tags": ["unsupervised", "image-translation"],
            "size": 23
          },
          {
            "id": "WGAN",
            "name": "WGAN",
            "fullName": "Wasserstein GAN",
            "category": "GAN",
            "year": 2017,
            "description": "Introduces Wasserstein distance for stable GAN training and meaningful loss metrics.",
            "mainIdea": "Uses Earth Mover’s distance to improve gradient behavior.",
            "metrics": {"citations": 18000, "influence": 10},
            "tags": ["stability", "theory", "training"],
            "size": 25
          },
          {
            "id": "WGAN-GP",
            "name": "WGAN-GP",
            "fullName": "Wasserstein GAN with Gradient Penalty",
            "category": "GAN",
            "year": 2017,
            "description": "Improves WGAN by replacing weight clipping with gradient penalty for enforcing Lipschitz constraint.",
            "mainIdea": "Adds gradient norm regularization to stabilize GAN training.",
            "metrics": {"citations": 15000, "influence": 9},
            "tags": ["stability", "gradient-penalty"],
            "size": 23
          },
          {
            "id": "BigGAN",
            "name": "BigGAN",
            "fullName": "Large-Scale Class-Conditional GAN",
            "category": "GAN",
            "year": 2018,
            "description": "Scales up GANs to large architectures with class conditioning and orthogonal regularization.",
            "mainIdea": "Large-batch training and hierarchical latent conditioning for high-fidelity generation.",
            "metrics": {"citations": 4000, "influence": 9},
            "tags": ["scalability", "class-conditional"],
            "size": 24
          },
          {
            "id": "StyleGAN2",
            "name": "StyleGAN2",
            "fullName": "Style-Based GAN v2",
            "category": "GAN",
            "year": 2020,
            "description": "Improves StyleGAN by removing artifacts and refining normalization.",
            "mainIdea": "Revises progressive growing, introduces path length regularization.",
            "metrics": {"citations": 7000, "influence": 10},
            "tags": ["style-control", "artifact-free"],
            "size": 25
          },
      
          {
            "id": "ScoreModel",
            "name": "Score-Based Model",
            "fullName": "Noise Conditional Score Network",
            "category": "Diffusion",
            "year": 2020,
            "description": "Trains a neural net to estimate ∇log p(x) (score) under noise perturbations; equivalent to diffusion.",
            "mainIdea": "Defines generative process via reverse-time SDE solving from noise to data.",
            "metrics": {"citations": 7000, "influence": 9},
            "tags": ["score-matching", "diffusion"],
            "size": 24
          },
          {
            "id": "GuidedDiffusion",
            "name": "Guided Diffusion",
            "fullName": "Classifier-Guided Diffusion",
            "category": "Diffusion",
            "year": 2021,
            "description": "Guides diffusion sampling using gradient of a classifier for controllable generation.",
            "mainIdea": "∇log p(y|x) term added to reverse process to guide toward class labels.",
            "metrics": {"citations": 4000, "influence": 9},
            "tags": ["conditional", "guidance"],
            "size": 22
          },
          {
            "id": "DALLE2",
            "name": "DALL·E 2",
            "fullName": "CLIP + Diffusion Text-to-Image Model",
            "category": "Diffusion",
            "year": 2022,
            "description": "Combines CLIP embeddings with diffusion decoder for text-to-image synthesis.",
            "mainIdea": "Latent representation from CLIP guides diffusion denoising decoder.",
            "metrics": {"citations": 5000, "influence": 10},
            "tags": ["text-to-image", "multimodal"],
            "size": 26
          },
          {
            "id": "Imagen",
            "name": "Imagen",
            "fullName": "Large Language-Guided Diffusion",
            "category": "Diffusion",
            "year": 2022,
            "description": "Uses T5 text encoder for conditioning diffusion models, achieving photorealism.",
            "mainIdea": "Language understanding fused with diffusion synthesis pipeline.",
            "metrics": {"citations": 3000, "influence": 10},
            "tags": ["text-to-image", "language-vision"],
            "size": 25
          },
          {
            "id": "SDXL",
            "name": "SDXL",
            "fullName": "Stable Diffusion XL",
            "category": "Diffusion",
            "year": 2023,
            "description": "Upgraded latent diffusion model with modular architecture and improved quality.",
            "mainIdea": "Refined UNet backbone and enhanced text encoder (OpenCLIP).",
            "metrics": {"citations": 500, "influence": 9},
            "tags": ["latent-space", "high-resolution"],
            "size": 25
          },
      
          {
            "id": "RealNVP",
            "name": "RealNVP",
            "fullName": "Real Non-Volume Preserving Flow",
            "category": "Flow",
            "year": 2017,
            "description": "Scalable normalizing flow using affine coupling layers.",
            "mainIdea": "Alternating masked transformations with tractable Jacobians.",
            "metrics": {"citations": 4000, "influence": 8},
            "tags": ["invertible", "flow"],
            "size": 20
          },
          {
            "id": "Glow",
            "name": "Glow",
            "fullName": "Generative Flow with Invertible 1x1 Convolutions",
            "category": "Flow",
            "year": 2018,
            "description": "Simplifies flow architectures via invertible 1x1 convolutions.",
            "mainIdea": "Efficient, exact likelihood computation and reversible mapping.",
            "metrics": {"citations": 5000, "influence": 8},
            "tags": ["invertible", "normalizing-flow"],
            "size": 22
          },
          {
            "id": "Flow++",
            "name": "Flow++",
            "fullName": "Improved Flow-Based Model",
            "category": "Flow",
            "year": 2019,
            "description": "Introduces variational dequantization and mixture coupling layers.",
            "mainIdea": "Enhances expressivity and sample fidelity of flow models.",
            "metrics": {"citations": 1000, "influence": 7},
            "tags": ["variational", "flow"],
            "size": 20
          },
      
          {
            "id": "VQ-GAN",
            "name": "VQ-GAN",
            "fullName": "Vector Quantized GAN",
            "category": "VAE",
            "year": 2021,
            "description": "Combines VQ-VAE discrete representations with adversarial loss for high-fidelity synthesis.",
            "mainIdea": "Trains autoencoder with perceptual + adversarial losses in latent space.",
            "metrics": {"citations": 4000, "influence": 10},
            "tags": ["discrete-latent", "hybrid", "gan"],
            "size": 25
          },
          {
            "id": "MaskGIT",
            "name": "MaskGIT",
            "fullName": "Masked Generative Image Transformer",
            "category": "Transformer",
            "year": 2022,
            "description": "Token-based parallel image generation inspired by masked language modeling.",
            "mainIdea": "Predicts masked tokens iteratively with bidirectional transformer.",
            "metrics": {"citations": 800, "influence": 9},
            "tags": ["transformer", "diffusion", "discrete"],
            "size": 22
          },
          {
            "id": "LCM",
            "name": "LCM",
            "fullName": "Latent Consistency Model",
            "category": "Diffusion",
            "year": 2023,
            "description": "Trains consistency functions in latent space for faster diffusion inference.",
            "mainIdea": "Achieves 10–20× faster generation than standard diffusion models.",
            "metrics": {"citations": 200, "influence": 8},
            "tags": ["consistency", "acceleration"],
            "size": 21
          },
          {
            "id": "EBM-Score",
            "name": "EBM",
            "fullName": "Energy-Based Model (Score Matching Revival)",
            "category": "EBM",
            "year": 2020,
            "description": "Revives classical energy-based modeling by learning unnormalized densities through score matching. Connects directly to modern diffusion models.",
            "mainIdea": "Trains neural network Eθ(x) to assign low energy to data and high energy to non-data; learns ∇xEθ(x) as data score.",
            "keyContributions": [
              "Revived energy-based learning via score matching",
              "Unified perspective with diffusion and flow models",
              "Demonstrated scalable training with Langevin dynamics"
            ],
            "papers": [
              {
                "title": "Energy-Based Models for Implicit Generation",
                "authors": ["LeCun, Y.", "Du, Y.", "Gao, T.", "Lee, H."],
                "year": 2020,
                "url": "https://arxiv.org/abs/1903.08689",
                "venue": "NeurIPS 2020"
              }
            ],
            "metrics": { "citations": 1500, "influence": 7 },
            "tags": ["energy-based", "score-matching", "implicit-generation"],
            "size": 20
          },
          {
            "id": "Diffusion-EBM",
            "name": "Diffusion-EBM",
            "fullName": "Diffusion Energy-Based Model",
            "category": "EBM",
            "year": 2022,
            "description": "Combines energy-based modeling with diffusion processes to stabilize training and improve controllability.",
            "mainIdea": "Learns energy landscape at each noise level of a diffusion process; bridges EBMs and denoising diffusion models.",
            "keyContributions": [
              "Unifies diffusion and energy-based learning",
              "Improves sample diversity and control",
              "Demonstrates diffusion as energy minimization"
            ],
            "papers": [
              {
                "title": "Diffusion Models as Energy-Based Models",
                "authors": ["Gao, R.", "Song, Y.", "Poole, B.", "Kingma, D."],
                "year": 2022,
                "url": "https://arxiv.org/abs/2206.01712",
                "venue": "ICML 2022"
              }
            ],
            "metrics": { "citations": 600, "influence": 8 },
            "tags": ["diffusion", "energy", "hybrid"],
            "size": 21
          }
    ],
    "links": [
        {
            "source": "VAE",
            "target": "Beta-VAE",
            "type": "improves-upon",
            "description": "Adds β parameter for disentanglement"
        },
        {
            "source": "VAE",
            "target": "VQ-VAE",
            "type": "variation-of",
            "description": "Replaces continuous latent space with discrete codebook"
        },
        {
            "source": "VQ-VAE",
            "target": "VQ-VAE-2",
            "type": "improves-upon",
            "description": "Adds hierarchy and autoregressive priors"
        },
        {
            "source": "GAN",
            "target": "DCGAN",
            "type": "improves-upon",
            "description": "Introduces convolutions and stabilizes training"
        },
        {
            "source": "DCGAN",
            "target": "StyleGAN",
            "type": "improves-upon",
            "description": "Revolutionary architecture with style control"
        },
        {
            "source": "VAE",
            "target": "StableDiffusion",
            "type": "used-in",
            "description": "VAE used for latent encoding/decoding"
        },
        {
            "source": "DDPM",
            "target": "StableDiffusion",
            "type": "improves-upon",
            "description": "Applies diffusion in latent space"
        },
        { "source": "VAE", "target": "CVAE", "type": "variation-of", "description": "Adds conditional variable for controlled generation" },
        { "source": "VAE", "target": "IWAE", "type": "improves-upon", "description": "Tightens ELBO via importance weighting" },
        { "source": "VAE", "target": "NVAE", "type": "improves-upon", "description": "Scales VAE architecture for high-resolution images" },
        { "source": "VAE", "target": "Diffusion-VAE", "type": "combines", "description": "Integrates diffusion into latent space" },
    
        { "source": "GAN", "target": "cGAN", "type": "variation-of", "description": "Adds conditional input" },
        { "source": "cGAN", "target": "Pix2Pix", "type": "variation-of", "description": "Supervised paired translation" },
        { "source": "Pix2Pix", "target": "CycleGAN", "type": "improves-upon", "description": "Enables unpaired translation" },
        { "source": "GAN", "target": "WGAN", "type": "improves-upon", "description": "Stabilizes training with Wasserstein loss" },
        { "source": "WGAN", "target": "WGAN-GP", "type": "improves-upon", "description": "Replaces weight clipping with gradient penalty" },
        { "source": "DCGAN", "target": "BigGAN", "type": "improves-upon", "description": "Scales architecture and adds class conditioning" },
        { "source": "StyleGAN", "target": "StyleGAN2", "type": "improves-upon", "description": "Removes artifacts and refines normalization" },
    
        { "source": "DDPM", "target": "ScoreModel", "type": "variation-of", "description": "Reformulates diffusion via score estimation" },
        { "source": "ScoreModel", "target": "GuidedDiffusion", "type": "improves-upon", "description": "Adds classifier-based conditioning" },
        { "source": "StableDiffusion", "target": "DALLE2", "type": "inspired-by", "description": "Uses CLIP embeddings for guidance" },
        { "source": "DALLE2", "target": "Imagen", "type": "improves-upon", "description": "Uses larger text encoder and better conditioning" },
        { "source": "StableDiffusion", "target": "SDXL", "type": "improves-upon", "description": "Upgraded version with modular components" },
        { "source": "DDPM", "target": "LCM", "type": "improves-upon", "description": "Faster generation via consistency training" },
    
        { "source": "RealNVP", "target": "Glow", "type": "improves-upon", "description": "Simplifies invertible layers using 1x1 convolutions" },
        { "source": "Glow", "target": "Flow++", "type": "improves-upon", "description": "Introduces variational dequantization" },
    
        { "source": "VQ-VAE", "target": "VQ-GAN", "type": "improves-upon", "description": "Adds adversarial loss to improve reconstruction quality" },
        { "source": "VQ-GAN", "target": "MaskGIT", "type": "used-in", "description": "Uses VQ-GAN codebook for discrete tokenization" },
        { "source": "StableDiffusion", "target": "LCM", "type": "improves-upon", "description": "Accelerates diffusion process in latent space" },
        {
            "source": "EBM-Score",
            "target": "Diffusion-EBM",
            "type": "improves-upon",
            "description": "Incorporates diffusion noise levels into energy modeling"
          },
          {
            "source": "ScoreModel",
            "target": "EBM-Score",
            "type": "similar-to",
            "description": "Score-based models share training objective with EBMs"
          },
          {
            "source": "DDPM",
            "target": "Diffusion-EBM",
            "type": "combines",
            "description": "Merges diffusion sampling with energy-based learning"
          }
    ]
}