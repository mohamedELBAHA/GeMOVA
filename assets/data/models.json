{
    "metadata": {
        "version": "1.0.0",
        "lastUpdated": "2024-01-15",
        "contributors": ["Your Name"],
        "description": "Interactive database of generative AI models"
    },
    "categories": {
        "VAE": {
            "name": "Variational Autoencoders",
            "color": "#3b82f6",
            "description": "Models based on variational encoding"
        },
        "GAN": {
            "name": "Generative Adversarial Networks",
            "color": "#22c55e",
            "description": "Models based on adversarial learning"
        },
        "Diffusion": {
            "name": "Diffusion Models",
            "color": "#f97316",
            "description": "Models based on diffusion and denoising"
        },
        "Transformer": {
            "name": "Transformer-based Models",
            "color": "#a855f7",
            "description": "Models based on Transformer architecture"
        },
        "Flow": {
            "name": "Flow-based Models",
            "color": "#2dd4bf",
            "description": "Models based on normalizing flows"
        },
        "EBM": {
            "name": "Energy-Based Models",
            "color": "#ef4444",
            "description": "Energy-based models"
        }
    },
    "linkTypes": {
        "improves-upon": {
            "label": "Improves",
            "color": "#6ee7b7",
            "description": "Direct improvement of the previous model"
        },
        "variation-of": {
            "label": "Variation of",
            "color": "#fca5a5",
            "description": "Variation or adaptation of the original model"
        },
        "used-in": {
            "label": "Used in",
            "color": "#c084fc",
            "description": "Component used in another model"
        },
        "inspired-by": {
            "label": "Inspired by",
            "color": "#fde047",
            "description": "Conceptual inspiration"
        },
        "combines": {
            "label": "Combines",
            "color": "#7dd3c0",
            "description": "Combines multiple approaches"
        }
    },
    "nodes": [
        {
            "id": "VAE",
            "name": "VAE",
            "fullName": "Variational Autoencoder",
            "category": "VAE",
            "year": 2013,
            "description": "Probabilistic generative model that learns a latent representation of data by maximizing a lower bound of the likelihood (ELBO). Combines an encoder that produces a latent distribution and a decoder that reconstructs the data.",
            "mainIdea": "Encode data into a probabilistic latent space (mean and variance) and decode to reconstruct. Uses the reparameterization trick to enable backpropagation through stochastic sampling.",
            "keyContributions": [
                "Introduction of the variational framework for autoencoders",
                "Reparameterization trick for training",
                "ELBO as objective function"
            ],
            "papers": [
                {
                    "title": "Auto-Encoding Variational Bayes",
                    "authors": ["Kingma, D.P.", "Welling, M."],
                    "year": 2013,
                    "url": "https://arxiv.org/abs/1312.6114",
                    "venue": "ICLR 2014"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/pytorch/examples/tree/master/vae"
                }
            ],
            "metrics": {
                "citations": 25000,
                "influence": 10
            },
            "tags": ["probabilistic", "unsupervised", "representation-learning"],
            "size": 30
        },
        {
            "id": "Beta-VAE",
            "name": "β-VAE",
            "fullName": "Beta-VAE",
            "category": "VAE",
            "year": 2017,
            "description": "Extension of VAE that encourages learning of disentangled representations by adding a hyperparameter β > 1 to the KL divergence term, forcing a more factorized representation.",
            "mainIdea": "Weight the KL term with β > 1 to force a more factorized representation in the latent space. Allows controlling the trade-off between reconstruction and disentanglement.",
            "keyContributions": [
                "Introduction of β parameter to control disentanglement",
                "Demonstration that β > 1 encourages factorized representations",
                "Metrics for evaluating disentanglement"
            ],
            "papers": [
                {
                    "title": "β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework",
                    "authors": ["Higgins, I.", "Matthey, L.", "Pal, A.", "et al."],
                    "year": 2017,
                    "url": "https://openreview.net/forum?id=Sy2fzU9gl",
                    "venue": "ICLR 2017"
                }
            ],
            "code": [
                {
                    "language": "TensorFlow",
                    "url": "https://github.com/google-research/disentanglement_lib"
                }
            ],
            "metrics": {
                "citations": 3500,
                "influence": 8
            },
            "tags": ["disentanglement", "interpretability", "representation-learning"],
            "size": 20
        },
        {
            "id": "VQ-VAE",
            "name": "VQ-VAE",
            "fullName": "Vector Quantized VAE",
            "category": "VAE",
            "year": 2017,
            "description": "VAE with discrete latent space using vector quantization. Replaces the continuous Gaussian distribution with a learned discrete codebook.",
            "mainIdea": "Use a codebook of discrete vectors and assign each encoding to the nearest vector. Enables better compression and avoids posterior collapse.",
            "keyContributions": [
                "Introduction of vector quantization in VAEs",
                "Straight-through estimator for backpropagation",
                "Better reconstruction quality than standard VAE"
            ],
            "papers": [
                {
                    "title": "Neural Discrete Representation Learning",
                    "authors": ["van den Oord, A.", "Vinyals, O.", "Kavukcuoglu, K."],
                    "year": 2017,
                    "url": "https://arxiv.org/abs/1711.00937",
                    "venue": "NeurIPS 2017"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/zalandoresearch/pytorch-vq-vae"
                }
            ],
            "metrics": {
                "citations": 4200,
                "influence": 9
            },
            "tags": ["discrete-latent", "compression", "quantization"],
            "size": 20
        },
        {
            "id": "VQ-VAE-2",
            "name": "VQ-VAE-2",
            "fullName": "Hierarchical VQ-VAE",
            "category": "VAE",
            "year": 2019,
            "description": "Hierarchical version of VQ-VAE with multiple levels of quantization to capture different scales of information.",
            "mainIdea": "Hierarchy of codebooks with autoregressive priors. The top level captures global structure, lower levels capture local details.",
            "keyContributions": [
                "Multi-scale hierarchical architecture",
                "Powerful autoregressive priors (PixelCNN)",
                "High-resolution quality image generation"
            ],
            "papers": [
                {
                    "title": "Generating Diverse High-Fidelity Images with VQ-VAE-2",
                    "authors": ["Razavi, A.", "van den Oord, A.", "Vinyals, O."],
                    "year": 2019,
                    "url": "https://arxiv.org/abs/1906.00446",
                    "venue": "NeurIPS 2019"
                }
            ],
            "metrics": {
                "citations": 1800,
                "influence": 7
            },
            "tags": ["hierarchical", "high-resolution", "autoregressive-prior"],
            "size": 18
        },
        {
            "id": "GAN",
            "name": "GAN",
            "fullName": "Generative Adversarial Network",
            "category": "GAN",
            "year": 2014,
            "description": "Revolutionary framework with two competing networks: a generator that creates synthetic data and a discriminator that distinguishes real from fake data.",
            "mainIdea": "Adversarial training via minimax game. Generator G minimizes log(1-D(G(z))) while discriminator D maximizes log(D(x)) + log(1-D(G(z))).",
            "keyContributions": [
                "Introduction of the adversarial paradigm",
                "Implicit generation without explicit likelihood",
                "Superior generation quality compared to previous models"
            ],
            "papers": [
                {
                    "title": "Generative Adversarial Nets",
                    "authors": ["Goodfellow, I.", "Pouget-Abadie, J.", "Mirza, M.", "et al."],
                    "year": 2014,
                    "url": "https://arxiv.org/abs/1406.2661",
                    "venue": "NeurIPS 2014"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/eriklindernoren/PyTorch-GAN"
                }
            ],
            "metrics": {
                "citations": 50000,
                "influence": 10
            },
            "tags": ["adversarial", "implicit-generation", "game-theory"],
            "size": 30
        },
        {
            "id": "DCGAN",
            "name": "DCGAN",
            "fullName": "Deep Convolutional GAN",
            "category": "GAN",
            "year": 2015,
            "description": "First stable GAN architecture using convolutions. Established architectural best practices for GANs.",
            "mainIdea": "Replace fully-connected layers with convolutions. Use transposed convolutions in G, strided convolutions in D, batch norm, and no pooling.",
            "keyContributions": [
                "Architectural guidelines for stable GANs",
                "Demonstration of meaningful learned representations",
                "Vector arithmetic in latent space"
            ],
            "papers": [
                {
                    "title": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks",
                    "authors": ["Radford, A.", "Metz, L.", "Chintala, S."],
                    "year": 2015,
                    "url": "https://arxiv.org/abs/1511.06434",
                    "venue": "ICLR 2016"
                }
            ],
            "metrics": {
                "citations": 15000,
                "influence": 9
            },
            "tags": ["convolutional", "architectural-guidelines", "stable-training"],
            "size": 22
        },
        {
            "id": "StyleGAN",
            "name": "StyleGAN",
            "fullName": "Style-based GAN",
            "category": "GAN",
            "year": 2018,
            "description": "Revolutionary GAN architecture enabling fine-grained and disentangled control of style at different spatial scales.",
            "mainIdea": "Mapping network f:Z→W followed by AdaIN to inject style at each layer. Enables separate control of coarse attributes (pose) and fine details (texture).",
            "keyContributions": [
                "Mapping network for more disentangled W latent space",
                "Style injection via Adaptive Instance Normalization",
                "Mixing regularization and hierarchical style control"
            ],
            "papers": [
                {
                    "title": "A Style-Based Generator Architecture for Generative Adversarial Networks",
                    "authors": ["Karras, T.", "Laine, S.", "Aila, T."],
                    "year": 2018,
                    "url": "https://arxiv.org/abs/1812.04948",
                    "venue": "CVPR 2019"
                }
            ],
            "code": [
                {
                    "language": "TensorFlow",
                    "url": "https://github.com/NVlabs/stylegan"
                }
            ],
            "metrics": {
                "citations": 8000,
                "influence": 10
            },
            "tags": ["style-control", "high-quality", "disentanglement"],
            "size": 25
        },
        {
            "id": "DDPM",
            "name": "DDPM",
            "fullName": "Denoising Diffusion Probabilistic Models",
            "category": "Diffusion",
            "year": 2020,
            "description": "Generative model based on inverting a diffusion process that progressively adds Gaussian noise to data.",
            "mainIdea": "Fixed forward process q(x_t|x_{t-1}) adding noise, learned reverse process p_θ(x_{t-1}|x_t) for denoising. Simplified objective: predict noise ε.",
            "keyContributions": [
                "Simplification of the variational objective",
                "Connection with score matching",
                "Superior quality compared to GANs on several metrics"
            ],
            "papers": [
                {
                    "title": "Denoising Diffusion Probabilistic Models",
                    "authors": ["Ho, J.", "Jain, A.", "Abbeel, P."],
                    "year": 2020,
                    "url": "https://arxiv.org/abs/2006.11239",
                    "venue": "NeurIPS 2020"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/hojonathanho/diffusion"
                }
            ],
            "metrics": {
                "citations": 7000,
                "influence": 10
            },
            "tags": ["denoising", "probabilistic", "score-based"],
            "size": 30
        },
        {
            "id": "StableDiffusion",
            "name": "Stable Diffusion",
            "fullName": "Latent Diffusion Model",
            "category": "Diffusion",
            "year": 2021,
            "description": "Diffusion in the latent space of a pre-trained VAE, drastically reducing computational costs while maintaining quality.",
            "mainIdea": "VAE encoder E compresses x→z, diffusion in latent space z, VAE decoder D reconstructs z→x. Cross-attention for textual conditioning.",
            "keyContributions": [
                "Efficient diffusion in latent space",
                "U-Net architecture with cross-attention",
                "Democratization of text-to-image generation"
            ],
            "papers": [
                {
                    "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
                    "authors": ["Rombach, R.", "Blattmann, A.", "Lorenz, D.", "et al."],
                    "year": 2021,
                    "url": "https://arxiv.org/abs/2112.10752",
                    "venue": "CVPR 2022"
                }
            ],
            "code": [
                {
                    "language": "PyTorch",
                    "url": "https://github.com/CompVis/stable-diffusion"
                }
            ],
            "metrics": {
                "citations": 5000,
                "influence": 10
            },
            "tags": ["latent-space", "text-to-image", "efficient"],
            "size": 25
        },
        {
            "id": "GPT",
            "name": "GPT",
            "fullName": "Generative Pre-trained Transformer",
            "category": "Transformer",
            "year": 2018,
            "description": "First large-scale language model using only the Transformer decoder architecture for autoregressive generation.",
            "mainIdea": "Unsupervised pre-training on next token prediction, then supervised fine-tuning. Decoder-only Transformer architecture with causal attention.",
            "keyContributions": [
                "Demonstration of large-scale generative pre-training",
                "Efficient transfer learning for NLP",
                "Decoder-only architecture for generation"
            ],
            "papers": [
                {
                    "title": "Improving Language Understanding by Generative Pre-Training",
                    "authors": ["Radford, A.", "Narasimhan, K.", "Salimans, T.", "Sutskever, I."],
                    "year": 2018,
                    "url": "https://openai.com/research/language-unsupervised",
                    "venue": "OpenAI Blog"
                }
            ],
            "metrics": {
                "citations": 10000,
                "influence": 9
            },
            "tags": ["language-model", "pre-training", "autoregressive"],
            "size": 30
        }
    ],
    "links": [
        {
            "source": "VAE",
            "target": "Beta-VAE",
            "type": "improves-upon",
            "description": "Adds β parameter for disentanglement"
        },
        {
            "source": "VAE",
            "target": "VQ-VAE",
            "type": "variation-of",
            "description": "Replaces continuous latent space with discrete codebook"
        },
        {
            "source": "VQ-VAE",
            "target": "VQ-VAE-2",
            "type": "improves-upon",
            "description": "Adds hierarchy and autoregressive priors"
        },
        {
            "source": "GAN",
            "target": "DCGAN",
            "type": "improves-upon",
            "description": "Introduces convolutions and stabilizes training"
        },
        {
            "source": "DCGAN",
            "target": "StyleGAN",
            "type": "improves-upon",
            "description": "Revolutionary architecture with style control"
        },
        {
            "source": "VAE",
            "target": "StableDiffusion",
            "type": "used-in",
            "description": "VAE used for latent encoding/decoding"
        },
        {
            "source": "DDPM",
            "target": "StableDiffusion",
            "type": "improves-upon",
            "description": "Applies diffusion in latent space"
        }
    ]
}